---
layout: page
#title: GazeTheWeb
#subtitle: Explore the Web with your eyes!
#use-site-title: true
---

<style>
  .github-corner:hover .octo-arm {
    animation: octocat-wave 560ms ease-in-out
  }

  @keyframes octocat-wave {

    0%,
    100% {
      transform: rotate(0)
    }

    20%,
    60% {
      transform: rotate(-25deg)
    }

    40%,
    80% {
      transform: rotate(10deg)
    }
  }

  @media (max-width:500px) {
    .github-corner:hover .octo-arm {
      animation: none
    }

    .github-corner .octo-arm {
      animation: octocat-wave 560ms ease-in-out
    }
  }
</style>

<div class="top">
  <img src="img/logoname.png" alt="gtw-logo" />
  <!--
    <img src="img/Logo.svg" alt="gtw-logo" />
    <h2>GazeTheWeb</h2>
    <h2>Explore the Web with your eyes!</h2>
  -->
</div>

<div id="download">
  <h2>Download</h2>
  <a href="https://github.com/MAMEM/GazeTheWeb/releases/latest">
    <button class="download-button">
      <img style="float:left;height: 50px; margin-top: 10px;" src="img/down-arrow.svg" alt="down-arrow">
      <span id="latestRelease">
        Latest Release
      </span>
    </button>
  </a>
  <div class="requirements">
    <h3>System-Requirements</h3>
    <ul>
      <li>Windows 7, 8, 8.1, or 10</li>
      <li>Graphics card with OpenGL 3.3 or higher support</li>
    </ul>

    <h3>Compatible eyetrackers</h3>
    <ul>
      <li>SMI RED-n series</li>
      <li>Visual Interactive myGaze n</li>
      <li>Tobii EyeX</li>
      <li>Tobii 4C</li>
    </ul>
  </div>
</div>

<div class="semanux">
  A part of the team behind GazeTheWeb is continuing to work on the innovation in a spin-off named <b>Semanux</b>. Visit <a href="https://semanux.com">https://semanux.com</a> for more details!
</div>

<hr>

<div class="information">

  <div id="whatIsGTW" class="whatIsGTW">

    <div class="screenshotGroup">
      <img class="screenshot zoomable" src="img/screenshots/Webpage.svg" alt="Webpage">
      <img class="screenshot zoomable" src="img/screenshots/Textinput.svg" alt="Textinput">
      <img class="screenshot zoomable" src="img/screenshots/Select.svg" alt="Select">
      <img class="screenshot zoomable" src="img/screenshots/Video.svg" alt="Video">
    </div>

    <h2>What is GazeTheWeb?</h2>
    <p>
      Information access and communication are among the main challenges that people aﬀected by severe disabilities have to face. Operations on Web pages are usually performed through conventional browser applications, controlled by input devices such as mouse or keyboard. We present <i>GazeTheWeb</i>, an open source framework to adopt Web pages for gaze interaction, where the input events (which are typically composed of mouse and keyboard interactions in generic applications) are revised to eye movements. In comparison to current approaches of additional browser extensions to include eye gaze events, we peruse a novel methodology of expanding <i>Chromium Embedded Framework</i> (CEF), which provides more utility and control to build eye controllable interfaces.
      <br>
      <br>
      GazeTheWeb supports unobtrusive gaze-based Web access by a browser incorporating efficient interface design and Web engineering. The browser interface is built upon gaze interaction paradigm, i.e., interface components such as size, shape, appearance, and feedback, which are vital to compensate eye tracking accuracy for input control. Additionally, the usage frequency of Web navigation (e.g., back, forward, click) has been considered for placement and positioning of elements. The Web engineering aspect examines the location of selectable objects on Web pages, such as text input ﬁelds, hyperlinks, scrollable sections, select ﬁelds, etc. The extracted elements are then represented with explicit and implicit indicators to be accessed by eye gaze input. GazeTheWeb browser has been released under an open source license, available on GitHub.
    </p>
    <div id="flyerDownload">
      <a href="downloads/GTW-Flyer.pdf">
        Download our flyer here
      </a>
    </div>

    <div id="imgContainer">
      <img class="imgCenter" src="img/GTW-Flyer_inside.png" alt="Eye-Tracking visualized">
    </div>
    <br>
    <div class="video" id="gtwVideo">
      <iframe allowFullScreen="allowFullScreen"
        src="https://www.youtube.com/embed/x1ESgaoQR9Y?ecver=1&amp;iv_load_policy=3&amp;rel=0&amp;yt:stretch=16:9&amp;autohide=1&amp;color=red&amp;width=560&amp;width=560"
        height="315" allowtransparency="true" frameborder="0">
        <script>function execute_YTvideo() { return youtube.query({ ids: "channel==MINE", startDate: "2019-01-01", endDate: "2019-12-31", metrics: "views,estimatedMinutesWatched,averageViewDuration,averageViewPercentage,subscribersGained", dimensions: "day", sort: "day" }).then(function (e) { }, function (e) { console.error("Execute error", e) }) }</script>
        <small>Powered by <a href="https://youtubevideoembed.com/ ">Embed YouTube Video</a></small>
      </iframe>
    </div>
  </div>
  <hr>
</div>

<div id="whatIsEyeTracking" class="whatIsEyeTracking">
  <h2>What is Eye-Tracking?</h2>
  <img src="img/Eyetracking.svg" alt="What is Eye-Tracking">
  <p>The eye-tracker illuminates the eyes of the user with infrared light and a camera records the eye movements. A calibraton provides an estimation of fixations of the user on the screen. We use the fixations for interaction with virtual buttons in the graphical interface of GazeTheWeb.
    <br>
    <br>
  </p>
  <hr>
</div>

<div id="story" class="story">
  <h2>Story</h2>
  <p>
    GazeTheWeb has been evaluated as part of the MAMEM project at three clinical cohorts in Athens, Thessaloniki, and Tel Aviv, in two trial phases. At the first trial phase in February 2017, 18 participants with motor impairment succesfully performed dictated tasks in the World Wide Web.
    <br>
    <br>
    <img src="img/phase1.svg" alt="phase1">
    <br>
    <br>
    The second phase has taken place in spring 2018, wheere 30 participants with motor impairment operated GazeTheWeb for one month a their homes on their own behalf. The system allowed the particitpants to browse the World Wide Web, perform communication, access entertainment and retrieve information.
    <br>
    <br>
    <img src="img/phase2.jpg" alt="phase2">
    <br>
  </p>
  <div class="video" id="mamemVideo">
    <iframe allowFullScreen="allowFullScreen"
      src="https://www.youtube.com/embed/42yGmr3NE0k?ecver=1&amp;iv_load_policy=3&amp;rel=0&amp;yt:stretch=16:9&amp;autohide=1&amp;color=red&amp;width=560&amp;width=560"
      height="315" allowtransparency="true" frameborder="0">
      <script>function execute_YTvideo() { return youtube.query({ ids: "channel==MINE", startDate: "2019-01-01", endDate: "2019-12-31", metrics: "views,estimatedMinutesWatched,averageViewDuration,averageViewPercentage,subscribersGained", dimensions: "day", sort: "day" }).then(function (e) { }, function (e) { console.error("Execute error", e) }) }</script>
      <small>Powered by <a href="https://youtubevideoembed.com/ ">Embed YouTube Video</a></small>
    </iframe>
  </div>
  <hr>
</div>

<div id="impact" class="impact">
  <h2>Impact</h2>
  <div class="awardGroup">
    <img class="awardImg" src="img/awards/w4a.svg" alt="w4a">
    <img class="awardImg" src="img/awards/www17.svg" alt="www17">
    <img class="awardImg" src="img/awards/dic.svg" alt="dic">
  </div>
  <p>
    If you use our software as part for your own research, please be kind and cite our publication:
  </p>

  <div id="citation">
    @inproceedings{tochiGazeTheWeb,<br>
    <div id="tabbed">
        author = {Menges, Raphael and Kumar, Chandan and Staab, Steffen},<br>
        title = {Improving User Experience of Eye Tracking-Based Interaction: Introspecting and Adapting Interfaces},<br>
        journal = {ACM Trans. Comput.-Hum. Interact.},<br>
        issue_date = {October 2019},<br>
        volume = {26},<br>
        number = {6},<br>
        month = nov,<br>
        year = {2019},<br>
        issn = {1073-0516},<br>
        pages = {37:1--37:46},<br>
        articleno = {37},<br>
        numpages = {46},<br>
        url = {http://doi.acm.org/10.1145/3338844},<br>
        doi = {10.1145/3338844},<br>
        acmid = {3338844},<br>
        publisher = {ACM},<br>
        address = {New York, NY, USA},<br>
        keywords = {Eye tracking, GazeTheWeb, Web accessibility, gaze interaction experience, gaze-based emulation, gaze-controlled interface, interface semantics, introspection},}<br>
    </div>
  </div>
  <hr>
</div>

<div id="people" class="people">
  <h2>People</h2>

  <img class="names" src="img/Names.svg" alt="names">
  <img class="framework" src="img/Framework.png" alt="framework">
  <hr>
</div>
</div>

<div id="imgViewer" class="modal">
  <img class="modal-content" id="img01">
</div>

<script>
  var modal = document.getElementById("imgViewer");
  var imgList = document.getElementsByClassName("zoomable");
  var modalImg = document.getElementById("img01");
  for (let img of imgList) {
    img.onclick = () => {
      modal.style.display = "block";
      modalImg.src = img.src;
    };
    img.style.cursor = "pointer";
    img.style.borderRadius = "5px";
    img.style.transition = "0.3s";
    img.onmouseover = () => {
      img.style.opacity = 0.7;
    }
    img.onmouseout = () => {
      img.style.opacity = 1;
    }
  };

  document.body.addEventListener('click',
    () => {
      modal.style.display = "none";
    },
    true);
</script>